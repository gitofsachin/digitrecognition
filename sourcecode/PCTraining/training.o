

    % Load MNIST.
    inputValues = loadMNISTImages('../../database/MNIST/train-images.idx3-ubyte');
    labels = loadMNISTLabels('../../database/MNIST/train-labels.idx1-ubyte');
    
    % Transform the labels to correct target values.
    targetValues = 0.*ones(10, size(labels, 1));
    for n = 1: size(labels, 1)
        targetValues(labels(n) + 1, n) = 1;
    end;
    
    % Choose form of MLP:
    numberOfHiddenUnits = 20;
    
    % Choose appropriate parameters.
    learningRate = 0.1;
    
    % Choose activation function.
    activationFunction = @logisticSigmoid;
    dActivationFunction = @dLogisticSigmoid;
    
    % Choose batch size and epochs. Remember there are 60k input values.
    batchSize = 100;
    epochs = 500;
    
    fprintf('Train twolayer perceptron with %d hidden units.\n', numberOfHiddenUnits);
    fprintf('Learning rate: %d.\n', learningRate);
    
    [hiddenWeights, outputWeights, error] = trainStochasticSquaredErrorTwoLayerPerceptron(activationFunction, dActivationFunction, numberOfHiddenUnits, inputValues, targetValues, epochs, batchSize, learningRate);
    
    fwrite1=fopen("hiddenweights1","w");
    fwrite2=fopen("outputweights1","w");

for i=1:numberOfHiddenUnits
fwrite(fwrite1,"{");
for j=1:784
fwrite(fwrite1,num2str(hiddenWeights(i,j)));
if (j~=784)
fwrite(fwrite1,",");
end;
end;
fwrite(fwrite1,"},\n");
end;

for i=1:10
fwrite(fwrite2,"{");
for j=1:numberOfHiddenUnits
fwrite(fwrite2,num2str(outputWeights(i,j)));
if (j~=numberOfHiddenUnits)
fwrite(fwrite2,",");
end;
end;
fwrite(fwrite2,"},\n");
end;

    fclose(fwrite1);
    fclose(fwrite2);
